{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eae4297-a08a-4a03-847a-bb69e66b48d2",
   "metadata": {},
   "source": [
    "# Gradient Descent for Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcca18d4-a610-4392-9fc2-2b5869c8788a",
   "metadata": {},
   "source": [
    "We will implement and Linear Regression with Cost Function and Gradient Descent\n",
    "\n",
    "### Tools\n",
    "\n",
    "We will use:\n",
    "* Numpy\n",
    "* Matplotlib\n",
    "* And some utils from COursera's Machine Learning Specialization Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44bcb058-4456-46fe-9f78-20409a226efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192ee28b-1a7f-4c81-a7de-95dcccca5de0",
   "metadata": {},
   "source": [
    "# Problem:\n",
    "\n",
    "Let's take these data points, a house with 1000 sqft sold at 300,000 dollars and a house with 2000 sqft sold for 500,000 dollars.\n",
    "\n",
    "| Size (1000 sqft) | Price (1000s of dollars) |\n",
    "|----------|----------|\n",
    "| 1 | 300 |\n",
    "| 2 | 500 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "137107cd-c668-4776-8aa4-1d0db50c6029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our data\n",
    "X_train = np.array([1.0,2.0]) # Features\n",
    "y_train = np.array([300.0, 500.0]) # Target Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8db49613-969a-4f10-859a-eb7edc859479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Cost (Mean Squared Error Cost)\n",
    "\n",
    "def compute_cost(x,y,w,b):\n",
    "    m = x.shape[0]\n",
    "    cost = 0\n",
    "    for i in range(m):\n",
    "        f_wb = w * x[i] + b\n",
    "        cost = cost + (f_wb - y[i]) ** 2\n",
    "    total_cost = 1 / (2 * m) * cost\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ace0f6-4fd3-4b27-8c47-1b8605403e3d",
   "metadata": {},
   "source": [
    "# My Understanding of Gradient Descent:  \n",
    "\n",
    "Gradient Descent can be used to minimize the cost function of any algorithm. \n",
    "\n",
    "The formula for Linear Regression is:\n",
    "\n",
    "$$\n",
    "f_{(w,b)}(x^i) = wx^{(i)} + b\n",
    "$$\n",
    "\n",
    "The formula for cost function for Linear Regression is:\n",
    "\n",
    "$$\n",
    "J_{(w,b)} = \\frac{1}{2m}\\sum_{i=0}^{m-1} (f_{w,b}(x^i) - y^i)^2 \\tag{1}\n",
    "$$\n",
    "\n",
    "Gradient Descent formula is:\n",
    "\n",
    "Repeat Until Convergence: { \n",
    "$$\n",
    "w = w - \\alpha * \\frac {\\partial J(w,b)}{\\partial w}\n",
    "$$\n",
    "$$\n",
    "b = b - \\alpha * \\frac {\\partial J(w,b)}{\\partial b}\n",
    "$$\n",
    "}\n",
    "\n",
    "where paramters w,b and updated simeltaneously\n",
    "\n",
    "The gradient is defined as:\n",
    "\n",
    "$$\n",
    "\\frac {\\partial J(w,b)}{\\partial w} = \\frac{1}{m} \\sum_{i=0}^{m=1}(f_{w,b}(x^{(i)}) - y^{(i)})x^{(i)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac {\\partial J(w,b)}{\\partial b} = \\frac{1}{m} \\sum_{i=0}^{m=1}(f_{w,b}(x^{(i)}) - y^{(i)})\n",
    "$$\n",
    "\n",
    "Here we can calculate the partial derivatives for all the paramters before updating any paramters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc57667-ad89-4c70-b1e4-7ad8ddad472d",
   "metadata": {},
   "source": [
    "# Implementing Gradient Descent\n",
    "\n",
    "We will implement gradient descent algorithm for one feature only\n",
    "\n",
    "We will use three functions:\n",
    "\n",
    "`compute_gradient:` For computing this formula $$\n",
    "\\frac {\\partial J(w,b)}{\\partial w} = \\frac{1}{m} \\sum_{i=0}^{m=1}(f_{w,b}(x^{(i)}) - y^{(i)})x^{(i)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac {\\partial J(w,b)}{\\partial b} = \\frac{1}{m} \\sum_{i=0}^{m=1}(f_{w,b}(x^{(i)}) - y^{(i)})\n",
    "$$\n",
    "\n",
    "`compute_cost`: For computing cost \n",
    "$$\n",
    "J_{(w,b)} = \\frac{1}{2m}\\sum_{i=0}^{m-1} (f_{w,b}(x^i) - y^i)^2 \\tag{1}\n",
    "$$\n",
    "\n",
    "`gradient_descent`: Utilizing both of the above functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e610659-8235-42e7-8c9a-41a5c4d9bc24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
